{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import autograd\n","import numpy as np \n","import scipy.stats as st\n","from autograd import numpy as np_grad\n","from autograd.scipy import stats as st_grad\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Think about evaluation Greeks for derivatives:\n","\n","If the pricing is analytical, the situation is straigt-forward: differentiate the function of a price and implement the partial derivative into code. With the use of numerical methods, one can even skip the manual differentiation part\n","\n","For Monte-Carlo pricing, everything is more complicated. The first idea that may come to mind the the following algoritm:\n","1) Calculate Monte-Carlo price of a derivative\n","2) Shift one risk factor by some small $h$\n","3) Calculate new Monte-Carlo price\n","4) Use numerical differentiation technique to determine the slope of a function\n","\n","Problem: both PVs generated by Monte-Carlo are essentially random variables. They get closer to the true value, but are still stochastic. Therefore, the slope between them would have large variance (far larger than two PVs by themselves). Actually, variance of the partial derivative evaluated this way will be:\n","\n","$$\n","Var(\\Delta) = Var\\left(\\frac{\\hat{C}_n(\\theta_0 + h) - \\hat{C}_n(\\theta_0)}{\\bar{h}}\\right) = \\frac{1}{\\bar{h}^2} Var(\\hat{C}_n(\\theta_0 + h) - \\hat{C}_n(\\theta_0)) = \\frac{1}{\\bar{h}^2} (Var(\\hat{C}_n(\\theta_0 + h)) + Var(\\hat{C}_n(\\theta_0))) = \\frac{2\\sigma^2}{n\\bar{h}^2} $$\n","\n","Therefore, $Var(\\Delta)$ depends:\n","\n","* Positively on $\\sigma$\n","* Negatively on $n$ (more simulations = higher precision, just like in regular Monte-Carlo)\n","* Negatively on $\\bar{h}$ (contradicts traditional calculus, in which lower shift positively affects the accuracy of the derivative estimation)\n","\n","However, higher $h$ increases bias of the simulated sensetivity $\\Rightarrow$ Bias-Variance Tradeoff\n","\n","=======================================================================================================================\n","\n","However, there is another way: it comes from Machine Learning and by essense is similar to the back-propogation: using chain rule to evaluate the derivative of the output to one of the inputs. It is called **Automatic Adjoint Differentiation**."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Delta of an option is equal to: 0.4496\n","Theta of an option is equal to: -0.0234\n","Vega of an option is equal to: 39.576\n","Rho of an option is equal to: 38.9247\n"]}],"source":["# before we move to the full scale Monte-Carlo approach, lets start with something simple: evaluating Greeks without explicitly defining them\n","\n","class call_option:\n","\n","    def __init__(self, spot, strike, T, vol, r):\n","        self.params =  np.array([spot, strike, T, vol, r])\n","\n","    def price(self, params):\n","        if params.all() == params.all():\n","            d1 = (np_grad.log(params[0] / params[1]) + (params[4] + params[3] ** 2 / 2) * params[2]) / (np_grad.sqrt(params[2]) * params[3])\n","            d2 = d1 - np_grad.sqrt(params[2]) * params[3]\n","            return params[0] * st_grad.norm.cdf(d1) - params[1] * np_grad.exp(-params[4] * params[2]) * st_grad.norm.cdf(d2)\n","        else:\n","            d1 = (np_grad.log(self.params[0] / self.params[1]) + (self.params[4] + self.params[3] ** 2 / 2) * self.params[2]) / (np_grad.sqrt(self.params[2]) * self.params[3])\n","            d2 = d1 - np_grad.sqrt(self.params[2]) * self.params[3]\n","            return self.params[0] * st_grad.norm.cdf(d1) - self.params[1] * np_grad.exp(-self.params[4] * self.params[2]) * st_grad.norm.cdf(d2)\n","    \n","    def delta(self):\n","        d1 = (np.log(self.params[0] / self.params[1]) + (self.params[4] + self.params[3] ** 2 / 2) * self.params[2]) / (np.sqrt(self.params[2]) * self.params[3])\n","        return st.norm.cdf(d1)\n","    \n","    def aad_first_order_greeks(self):\n","        nabla_f = autograd.grad(self.price)\n","        greeks = nabla_f(self.params)\n","        # print(greeks)\n","        print(f\"Delta of an option is equal to: {np.round(greeks[0], 4)}\")\n","        print(f\"Theta of an option is equal to: {-np.round(greeks[2] / 252, 4)}\")\n","        print(f\"Vega of an option is equal to: {np.round(greeks[3], 4)}\")\n","        print(f\"Rho of an option is equal to: {np.round(greeks[4], 4)}\")\n","    \n","    def aad_second_order_greeks(self):\n","        hess_f = autograd.hessian(self.price)\n","        greeks = hess_f(self.params)\n","        # print(greeks)\n","        print(f\"Gamma of an option is equal to: {np.round(greeks[0][0], 4)}\")\n","        print(f\"Vanna of an option is equal to: {np.round(greeks[0][3], 4)}\")\n","        print(f\"Volga of an option is equal to: {np.round(greeks[3][3], 4)}\")\n","        print(f\"Charn of an option is equal to: {-np.round(greeks[0][2], 4)}\")\n","\n","call_option(100.0, 110.0, 1.0, 0.2, 0.05).aad_first_order_greeks()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0.44618391 -0.35195489 -0.29516769 38.71503758 38.72972613]\n","Delta of an option is equal to: 0.4462\n","Theta of an option is equal to: -0.0012\n","Vega of an option is equal to: 38.7297\n","Rho of an option is equal to: 38.715\n"]}],"source":["\n","def gbm(params):\n","    spot, strike, T, r, vol = params[0], params[1], params[2], params[3], params[4]\n","    T_days = int(np_grad.round(T * 252, 0))\n","    arr = st.norm.rvs(size = (T_days, 10000))\n","    paths = arr * (vol / np_grad.sqrt(252)) + (r - vol ** 2 / 2) / 252\n","    paths = paths.cumsum(axis = 0)\n","    paths = spot * np_grad.exp(paths)\n","    return np_grad.fmax(paths[-1,:] - strike, 0) / np_grad.exp(r * T)\n","\n","# grad = autograd.jacobian(gbm)\n","# greeks = grad(np.array([100, 110, 1, 0.05, 0.2]))\n","# print(greeks[:, 0].mean())\n","\n","grad = autograd.elementwise_grad(gbm)\n","greeks = grad(np.array([100, 110, 1, 0.05, 0.2])) / 10000\n","print(greeks)\n","\n","print(f\"Delta of an option is equal to: {np.round(greeks[0], 4)}\")\n","print(f\"Theta of an option is equal to: {np.round(greeks[2] / 252, 4)}\")\n","print(f\"Vega of an option is equal to: {np.round(greeks[4], 4)}\")\n","print(f\"Rho of an option is equal to: {np.round(greeks[3], 4)}\")\n","\n","# plt.plot(gbm([0.05, 0.2]))\n","# plt.show()"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["# before we move to the full scale Monte-Carlo approach, lets start with something simple: evaluating Greeks without explicitly defining them\n","\n","class call_option:\n","\n","    def __init__(self, spot, strike, T, vol, r, N = 0):\n","        self.params =  np.array([spot, strike, T, vol, r])\n","        self.N = N\n","\n","    def price(self, params = []):\n","        if len(params) != 0:\n","            d1 = (np_grad.log(params[0] / params[1]) + (params[4] + params[3] ** 2 / 2) * params[2]) / (np_grad.sqrt(params[2]) * params[3])\n","            d2 = d1 - np_grad.sqrt(params[2]) * params[3]\n","            return params[0] * st_grad.norm.cdf(d1) - params[1] * np_grad.exp(-params[4] * params[2]) * st_grad.norm.cdf(d2)\n","        else:\n","            d1 = (np_grad.log(self.params[0] / self.params[1]) + (self.params[4] + self.params[3] ** 2 / 2) * self.params[2]) / (np_grad.sqrt(self.params[2]) * self.params[3])\n","            d2 = d1 - np_grad.sqrt(self.params[2]) * self.params[3]\n","            return self.params[0] * st_grad.norm.cdf(d1) - self.params[1] * np_grad.exp(-self.params[4] * self.params[2]) * st_grad.norm.cdf(d2)\n","    \n","    def delta(self):\n","        d1 = (np.log(self.params[0] / self.params[1]) + (self.params[4] + self.params[3] ** 2 / 2) * self.params[2]) / (np.sqrt(self.params[2]) * self.params[3])\n","        return st.norm.cdf(d1)\n","    \n","    def aad_first_order_greeks(self):\n","        nabla_f = autograd.grad(self.price)\n","        greeks = nabla_f(self.params)\n","        # print(greeks)\n","        print(f\"Delta of an option is equal to: {np.round(greeks[0], 4)}\")\n","        print(f\"Theta of an option is equal to: {-np.round(greeks[2] / 252, 4)}\")\n","        print(f\"Vega of an option is equal to: {np.round(greeks[3], 4)}\")\n","        print(f\"Rho of an option is equal to: {np.round(greeks[4], 4)}\")\n","    \n","    def aad_second_order_greeks(self):\n","        hess_f = autograd.hessian(self.price)\n","        greeks = hess_f(self.params)\n","        # print(greeks)\n","        print(f\"Gamma of an option is equal to: {np.round(greeks[0][0], 4)}\")\n","        print(f\"Vanna of an option is equal to: {np.round(greeks[0][3], 4)}\")\n","        print(f\"Volga of an option is equal to: {np.round(greeks[3][3], 4)}\")\n","        print(f\"Charn of an option is equal to: {-np.round(greeks[0][2], 4)}\")\n","\n","    def price_monte_carlo(self, params = []):\n","\n","        if self.N == 0:\n","            raise ValueError(\"Enter positive number of paths\")\n","\n","        if len(params) != 0:\n","            spot, strike, T, vol, r = params[0], params[1], params[2], params[3], params[4]\n","        else:\n","            spot, strike, T, vol, r = self.params[0], self.params[1], self.params[2], self.params[3], self.params[4]\n","\n","        arr = st.norm.rvs(size = (1, 100000))\n","        paths = arr * (vol * np_grad.sqrt(T)) + (r - vol ** 2 / 2) * T\n","        paths = spot * np_grad.exp(paths)\n","        return (np_grad.fmax(paths - strike, 0) / np_grad.exp(r * T)).mean()\n","        \n","    def aad_mc_first_order_greeks(self):\n","        greeks = autograd.elementwise_grad(self.price_monte_carlo)(self.params)\n","        # print(f\"Delta of an option is equal to: {np.round(greeks[0], 4)}\")\n","        # print(f\"Theta of an option is equal to: {-np.round(greeks[2] / 252, 4)}\")\n","        # print(f\"Vega of an option is equal to: {np.round(greeks[3], 4)}\")\n","        # print(f\"Rho of an option is equal to: {np.round(greeks[4], 4)}\")\n","    \n","    def aad_mc_second_order_greeks(self):\n","        hess_f = autograd.hessian(self.price_monte_carlo)\n","        greeks = hess_f(self.params)\n","        return greeks"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["8.44 ms ± 480 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"]}],"source":["%%timeit\n","call_option(100.0, 110.0, 1.0, 0.2, 0.05, 1_000_000).aad_mc_first_order_greeks()"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Delta of an option is equal to: 0.4503\n","Theta of an option is equal to: -0.0234\n","Vega of an option is equal to: 39.5552\n","Rho of an option is equal to: 38.9944\n"]}],"source":["call_option(100.0, 110.0, 1.0, 0.2, 0.05, 1_000_000).aad_mc_first_order_greeks()"]},{"cell_type":"code","execution_count":159,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.00000000e+00,  0.00000000e+00,  3.94023593e-02,\n","         3.94023593e-01, -1.11022302e-16],\n","       [ 0.00000000e+00,  0.00000000e+00,  1.76167689e-02,\n","         0.00000000e+00,  3.52335379e-01],\n","       [ 3.94023593e-02,  1.76167689e-02, -2.01764652e+00,\n","         2.01948164e+01,  3.68190471e+01],\n","       [ 3.94023593e-01,  0.00000000e+00,  2.01948164e+01,\n","         4.93636729e+00,  0.00000000e+00],\n","       [ 0.00000000e+00,  3.52335379e-01,  3.68190471e+01,\n","         0.00000000e+00, -3.87568917e+01]])"]},"execution_count":159,"metadata":{},"output_type":"execute_result"}],"source":["call_option(100.0, 110.0, 1.0, 0.2, 0.05, 1000000).aad_mc_second_order_greeks()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":2}
